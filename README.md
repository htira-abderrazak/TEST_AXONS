This script is writen in Python it takes a video.mp4 as an input and displays a graph that depicts the amount of stress using a variety of parameters, including blinks, body movements, sound, and hand movements.

The input must be a sound-tracked MP4 video with only a human upper part and good resolution.

the models used in this project are pre-trained model from opencv such as haarcascade_eye and haarcascade_frontalface_default.
